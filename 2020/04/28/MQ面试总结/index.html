<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> “MQ面试总结” · pinkDonkey</title><meta name="description" content="I'm a little pink donkey that keeps going ..."><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/jekyll.css"><!--[if lt IE 9]>
<script src="js/html5shiv.min.js"></script>
<script src="js/respond.min.js"></script>
<![endif]--><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="pinkDonkey" type="application/atom+xml">
</head><body><header class="row-flex-row limit-width vh-center"><a href="/" class="logo"><img src="/favicon.png"></a><nav><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-link">Home</a></li><li class="nav-list-item"><a href="/archives/" class="nav-link active">   Blog</a></li><li class="nav-list-item"><a href="https://github.com/pinkDonkey190610" target="_blank" class="nav-link">github</a></li><li class="nav-list-item"><a href="http://weibo.com/7447881909" target="_blank" class="nav-link">weibo</a></li></ul></nav></header><div class="container limit-width"><section class="row-flex-row"><div class="post"><article class="post-block"><h2 class="post-title"><a href="/2020/04/28/MQ%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/" class="post-title-link">“MQ面试总结”</a></h2><div class="post-meta"><ul class="post-tag-list"><li class="post-tag-item"><a href="/tags/面试/" class="post-tag-link">面试</a></li></ul><div class="post-time">Tuesday, April 28th 2020</div></div><div class="post-content"><p>消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠性、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。当今市面上有很多主流的消息中间件，如老牌的ActiveMQ、RabbitMQ，炙手可热的Kafka，阿里巴巴自主开发RocketMQ等。</p>
<a id="more"></a>

<h2 id="MQ的组成"><a href="#MQ的组成" class="headerlink" title="MQ的组成"></a>MQ的组成</h2><p>1、Broker：消息服务器，作为server提供消息核心服务；<br>2、Producer：消息生产者，业务的发起方，负责生产消息传输给Broker<br>3、Consumer：消息消费者，业务的处理方，负责从Broker获取消息并进行业务逻辑处理；<br>4、Topic：主题，发布订阅模式下的统一汇集地，不同生产者向Topic发送消息，由MQ服务器分发到不同的订阅者，实现消息的广播；<br>5、Queue：队列，点对点模式下，特定的生产者向特定Queue发送消息，消费者订阅特定的Queue完成指定消息的接收；<br>6、Message：消息体，根据不同通讯协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传递。</p>
<h2 id="消息的传递类型"><a href="#消息的传递类型" class="headerlink" title="消息的传递类型"></a>消息的传递类型</h2><p>1、点对点：使用Queue作为通讯载体，消息生产者生成消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。消息被消费以后，Queue中不再存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只有一个消费者可以消费。<br><img src="/images/MQ-1.png" height="555px"><br>2、发布/订阅：使用Topic作为通讯载体，消息生产者（发布）将消息发布到Topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到Topic的消息会被所有的订阅者消费。<br><img src="/images/MQ-2.png" height="555px"><br>两者的区别：Queue实现负载均衡，将Producer生产的消息发送到消息队列中，由多个消费者消费。但一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者；Topic实现了发布和订阅，当你发布一个消息，所有订阅这个Topic的服务都能的得到这个消息，所以1到N个订阅者都能得到一个消息的拷贝。</p>
<h2 id="MQ优缺点"><a href="#MQ优缺点" class="headerlink" title="MQ优缺点"></a>MQ优缺点</h2><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>1、解耦：一个业务需要多个模块共同实现，或者一条消息有多个系统需要对应处理，只需要主业务完成之后，发送一条MQ，其余模块消费MQ消息，即可实现业务，降低模块之间的耦合。<br>2、异步：主业务执行结束后从属业务通过MQ异步执行，减低业务的响应时间，提高用户体验。<br>3、消峰：高并发情况下，MQ-client提供拉模式，根据自己的处理能力，每隔一段时间或每次拉取若干条消息，实施流控，达到下游自我保护的作用，可以提高高峰期业务处理的能力，避免系统瘫痪。</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>1、系统可用性降低：系统引入的外部依赖越多，越容易挂掉，需考虑MQ瘫痪的情况。<br>2、系统复杂性提高：需要考虑消息丢失、消息重复消费、消息传递的顺序性等问题。<br>3、系统存在一致性问题：需考虑主、从业务一致性处理。</p>
<h2 id="不同MQ之间的区别"><a href="#不同MQ之间的区别" class="headerlink" title="不同MQ之间的区别"></a>不同MQ之间的区别</h2><table>
<thead>
<tr>
<th align="center">特性</th>
<th align="center">ActiveMQ</th>
<th align="center">RabbitMQ</th>
<th align="center">RocketMQ</th>
<th align="center">Kafka</th>
</tr>
</thead>
<tbody><tr>
<td align="center">单机吞吐量</td>
<td align="center">万级</td>
<td align="center">万级</td>
<td align="center">十万级</td>
<td align="center">十万级</td>
</tr>
<tr>
<td align="center">Topic数量对吞吐量的影响</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">Topic可达到几百、几千的级别，吞吐量增加后有较小幅度的下降（优势）</td>
<td align="center">Topic从几百到几千时，吞吐量会大幅度下降</td>
</tr>
<tr>
<td align="center">时效性</td>
<td align="center">毫秒级</td>
<td align="center">微秒级（优势）</td>
<td align="center">毫秒级</td>
<td align="center">毫秒级</td>
</tr>
<tr>
<td align="center">可用性</td>
<td align="center">高，基于主从架构实现高可用性</td>
<td align="center">高，基于主从架构实现高可用性</td>
<td align="center">非常高，分布式架构</td>
<td align="center">非常高，Kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td>
</tr>
<tr>
<td align="center">消息可靠性</td>
<td align="center">有较低的概率丢失数据</td>
<td align="center"></td>
<td align="center">经过参数优化设置，可以做到零丢失</td>
<td align="center">经过参数优化设置，可以做到零丢失</td>
</tr>
<tr>
<td align="center">功能支持</td>
<td align="center">MQ领域的功能极其完备</td>
<td align="center">基于erlang开发，所以并发能力很强，性能机器好，延时很低</td>
<td align="center">MQ功能较为完善，还是分布式的，扩展性好</td>
<td align="center">功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准</td>
</tr>
<tr>
<td align="center">优势</td>
<td align="center">非常成熟，功能强大，在业内大量的公司以及项目中都有应用</td>
<td align="center">erlang语言开发，性能极其好，延时很低。吞吐量到万级，MQ功能比较完备。开源提供的管理界面非常棒。社区相对比较活跃，几乎每个月都发布几个版本。国内一些互联网公司用的也比较多</td>
<td align="center">接口简单易用，阿里大规模应用过。日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展很方便，社区维护还可以，可靠性和可用性都不错，还可以支持大规模的Topic数量，支持复杂MQ业务场景。Java编写，源码便于阅读</td>
<td align="center">Kafka仅仅提供较少的核心功能，但是提供超高的吞吐量，毫秒级的延迟，极高的可用性和可靠性，分布式易扩展。Kafka最好是支撑较少的Topic数量，以保证其超高的吞吐量</td>
</tr>
<tr>
<td align="center">劣势</td>
<td align="center">偶尔会有较低概率丢失消息。社区活跃度逐渐降低、国内应用也越来越少，官方对ActiveMQ 5.x维护越来越少，几个月才发布一个版本。主要基于解耦和异步来用，较少在大规模吞吐的场景中使用</td>
<td align="center">实现机制比较重，吞吐量相比低一些。erlang语言开发，很难有实力去源码级别研究与定制。RabbitMQ集群动态扩展很麻烦</td>
<td align="center">社区活跃度相对一般，文档相对简单一些，接口不是按照标准JMS规范，有些系统要迁移时需要大量修改代码</td>
<td align="center">消息可重复消费，会对消息准确性造成极其细微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略，这个特性天然适合大数据实时计算以及日志采集</td>
</tr>
</tbody></table>
<p>综上所述：中小型公司，技术实力较为一般，技术挑战不是特别高，用RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择；大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，几乎是全世界这个领域的事实性规范。</p>
<h2 id="MQ常见问题解决方案"><a href="#MQ常见问题解决方案" class="headerlink" title="MQ常见问题解决方案"></a>MQ常见问题解决方案</h2><h4 id="引入MQ后，如何保证其高可用性？"><a href="#引入MQ后，如何保证其高可用性？" class="headerlink" title="引入MQ后，如何保证其高可用性？"></a>引入MQ后，如何保证其高可用性？</h4><p>1、RabbitMQ的高可用性（基于主从做高可用性）：<br>RabbitMQ有三种模式：单机模式、普通集群模式、镜像集群模式<br>a、单机模式：就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式（无高可用性）<br>b、普通集群模式：就是在多台机器上启动多个RabbitMQ实例，每个机器上启动一个，但是创建Queue时，只会放在一个RabbitMQ实例上，其他的每个实例都同步Queue的元数据。消费的时候，若连接到未存放Queue的实例，则该实例会从Queue所在实例上拉取数据过来（就是个普通的集群，未做到分布式，在消费消费时，有两种方式，要不消费者每次随机连接一个实例然后拉取数据，要不固定连接那个Queue所在的实例消费数据，前者有数据拉取的开销，后者存在单实例性能瓶颈的问题；若存放Queue的实例宕机了，会导致接下来其它实例无法从那个宕机的实例拉取数据，若开启了消息持久化，让RabbitMQ落地存储消息，消息不一定会丢，得等这个实例恢复了，才可以继续从这个Queue拉取数据；这个方案没有什么高可用可言，主要就是提高吞吐量的，就是让集群中多个节点来服务某个Queue的读写）<br>c、镜像集群模式：这种模式，才是所谓的RabbitMQ的高可用模式，与普通集群模式不同的就是，你创建的Queue，无论元数据还是Queue里面的消息都会存在于多个实例上，然后你每次写消息到Queue的时候，都会自动把消息同步到其他实例的Queue（好处：任何一台机器宕机，其他机器都包含完整的消息，可以继续使用。坏处：1、性能开销太大，消息同步到所有机器，导致网络带宽压力和消耗很重。2、没有扩展性可言，如果某个Queue负载过重，加机器，新增的机器也包含了这个Queue的所有数据，并没有办法线性扩展Queue（解决方法其实很简单，RabbitMQ有很好用的管理控制台，可以后台新增一个策略，这个策略是镜像集群模式的策略，可以要求数据同步到所有节点、也可以要求只同步到指定数量的节点，然后你再次创建Queue的时候，应用这个策略，就会自动将数据同步到其它的节点上去了））<br>2、Kafka的高可用：<br>多个Broker组成，每个Broker是一个节点；你每创建一个Topic,这个Topic可以划分为多个Partition，每个Partition可以存在于不同的Broker上，每个Partition就放一部分数据。这就是天然的分布式消息队列，就是说一个Topic的数据，是分散放在多个机器上的，每个机器放一部分数据（实际上RabbitMQ之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA机制而已，因为无论怎么玩儿，RabbitMQ一个Queue的数据都是放在一个节点里的，像镜像集群下，也是每个节点都放这个Queue的完整数据），Kafka0.8以前没有HA机制， 就是任何一个Broker宕机，那么Broker上的Partition就废了，无法读写，无高可用可言。Kafka0.8以后提供了HA机制，就是Replica副本机制，每个Partition的数据都会同步到其他机器上，形成自己的多个Replica副本，然后从所有的Replica会选举出一个Leader出来，生产和消费都会与这个Leader打交道，其他的Replica就是Follower，写的时候，Leader会负责把消息同步到所有的Follower上去，读的时候就直接读Leader上数据即可（为何只能读Leader，很简单，要是可以随意读写每个Follower，那么就要关心数据一致性的问题，系统复杂性太高，很容易出问题）Kafka会均匀的将一个Partition的所有Replica分布在不同的机器上，这样可以提高容错性。如果某个Broker宕机了并不会有太大问题，因为Broker上面的Partition在其他机器上都有副本的，如果这上面有某个Partition的Leader，那么此时会重新选举出一个新的Leader出来，继续读写这个新的Leader即可，这就是所谓的高可用性。写数据的时候，生产者就写Leader，然后Leader将数据落地写入本地磁盘，接着其它Follower自己主动从Leader来pull数据。一旦所有Follower同步好数据，就会发送ack给Leader，Leader收到所有Follower的ack之后，就会返回写成功的消息给生产者（这只是其中一种模式）消费的时候，只会从Leader去读，但是只有一个消息已经被所有Follower都同步成功返回ack的时候，这个消息才会被消费者读到 </p>
<h4 id="引入MQ后，如何保证消息消费时的幂等性？"><a href="#引入MQ后，如何保证消息消费时的幂等性？" class="headerlink" title="引入MQ后，如何保证消息消费时的幂等性？"></a>引入MQ后，如何保证消息消费时的幂等性？</h4><p>1、为何会出现消息重复消费的情况？<br>以Kafka举例，其存在一个offset的概念，就是每个消息写进去都有一个offset来代表它的序号，然后Consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，通知Kafka这些消息已经被消费过了，如果我重启了什么的，就继续上次消费到的offset来继续消费。若在offset还未提交的时候，进程被kill掉了，那么就会造成Consumer明明已经消费了某些消息，但Kafka并不会接收到offset通知，此时若重启，那么Kafka就会按照已经接收到的offset来判断消息消费的起点，那么已经消费却未成功发送offset的消息就会被再次消费，造成消息重复消费的问题<br>2、如何保证消息队列的幂等性？<br>保证MQ的消费是幂等性的，需要结合具体的业务来看，简单举例几种情况：<br>a、比如你拿个数据要写库操作，那么你可以先根据主键查一下，如果这个数据已经存在，那么就不插入，只需要update一下就好<br>b、比如你是写入Redis的，那没问题，反正每次都是set，天然幂等性<br>c、若不是上面两种场景，你可以让生产者发送数据的时候加一个全局唯一的id，类似订单id之类的东西，然后你消费的时候，先根据id去比如Redis里查一下之前是否消费过？若未消费过，就继续处理，然后这个id写入Redis，若已经消费过，就不进行后续处理，保证相同消息不被重复消费即可<br>d、基于数据库唯一键来保证重复数据不会重复插入多条</p>
<h4 id="引入MQ后，如何保证消息的可靠性传输？"><a href="#引入MQ后，如何保证消息的可靠性传输？" class="headerlink" title="引入MQ后，如何保证消息的可靠性传输？"></a>引入MQ后，如何保证消息的可靠性传输？</h4><p>MQ的消息丢失一般分为三种：生产者弄丢了消息、MQ自己弄丢了消息、消费者弄丢了消息<br>1、RabbitMQ一般来说都是承载公司核心业务的，数据是绝对不能丢失的<br>a、生产者弄丢了消息：生产者写消息的过程中，消息还没到RabbitMQ在网络传输过程中就丢失了或者消息到了RabbitMQ，但MQ内部出错，没保存下了，消息丢失了<br>解决方案：<br>1&gt;使用RabbitMQ提供的事务功能：生产者发送消息之前开启RabbitMQ事务（channel.txSelect），然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就执行事务回滚（channel.txRollback），然后重试发送消息；如果成功收到了消息，那么可以提交事务（channel.txCommit）。但是RabbitMQ一旦开启事务，吞吐量就会受到很大影响，因为太耗性能。<br>2&gt;使用confirm模式：生产者开启confirm模式后，每次写消息都会分配一个唯一的id，然后如果成功写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，通知你这个消息接收成功了；如果RabbitMQ没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败了，可以重试发送。而且我们可以结合这个机制在内存里维护每个消息id的状态，如果超过一段时间还没接收到这个消息的回调，就可以重发。<br>区别：事务机制是同步的，提交一个事务之后会处于阻塞状态；confirn机制是异步的，你发送一个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你的一个接口通知你这个消息已经成功接收了。所以一般在生产者这块避免数据丢失，都是选用confirm机制<br>b、MQ自己弄丢了消息:解决方案是开启RabbitMQ的持久化，就是消息写入之后会持久化到磁盘，哪怕RabbitMQ挂掉，恢复之后会自动读取之前存储的数据，一般数据不会丢失。除非极其罕见的RabbitMQ还没持久化到磁盘就挂掉了，可能会导致少量数据的丢失，但这个概率很低；设置持久化有两个步骤：1、创建Queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化Queue的元数据，但不会持久化Queue里面的数据。2、发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。必须同时设置两个持久化才行，RabbitMQ哪怕是挂掉了，再次重启，也会从磁盘上重启Queue，恢复这个Queue里的数据；持久化可以跟生产者的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack，所以哪怕是在持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，也会重发消息<br>c、消费者弄丢了消息:主要是因为消费的时候，刚消费到，还没处理，结果进程就挂了，比如重启，RabbitMQ认为你已经消费了消息，这条数据就丢了；解决方案是使用RabbitMQ提供的ack机制，就是关闭RabbitMQ的自动ack，通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，在程序里ack。这样的话，如果没处理完，就没有ack，RabbitMQ就认为你没处理完成，RabbitMQ就会把这个消息分配给其他的Consumer去处理，消息是不会丢失的<br>2、Kafka<br>a、消费者弄丢了消息：唯一可能导致消费者丢失数据的情况就是消费者消费了这个消息，然后自动提交了offset，让Kafka认为已经消费好了这个消息，但很巧的是，你刚准备处理这个消息，还没处理，就挂掉了，此时这条消息就丢失了；解决方案就是关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢失。但此时会有重复消费的问题，比如你刚处理完，还没提交offset就挂掉了，此时肯定会重复消费一次，所以需要自己保证幂等性<br>b、MQ自己弄丢了消息：这是个比较常见的场景，就是Kafka某个Broker宕机，然后重新选举Partition的Leader时，若其他的Follower刚好还有些数据没有同步，然后某个Follower被选为Leader，就会造成消息的丢失<br>解决方案就是设置4个参数，这样配置，至少在Kafka Broker端就可以保证在Leader所在Broker发生故障，进行Leader切换时，数据不会丢失：<br>1、给这个Topic设置replication.factor参数：这个值必须大于1，要求每个Partition必须有至少两个副本<br>2、在Kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求Leader至少感知到有一个Follower还跟自己保持联系，没掉队，这样才能确保Leader挂了还有一个Follower<br>3、在Producer端设置acks=all:这个是要求每条数据，必须是写入所有的Replica之后，才能认为是写成功了<br>4、在Producer端设置retries=MAX（无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了<br>c、生产者不会弄丢了消息：如果按照上述的思路设置了acks=all，一定不会丢，要求是你的Leader接收到消息，所有的Follower都同步到了消息之后，才认为本次写操作成功，如果没有满足这个条件，生产者会自动无限次重试</p>
<h4 id="引入MQ后，如何保证消息的顺序性？"><a href="#引入MQ后，如何保证消息的顺序性？" class="headerlink" title="引入MQ后，如何保证消息的顺序性？"></a>引入MQ后，如何保证消息的顺序性？</h4><p>保证消息的顺序性是一个比较常见的需求，比如一个MySQL Binlog同步系统，你在一台MySQL里对一条数据分别进行了增、改、删三种操作，对应的会有三条Binlog，接着这三条binlog会发送到MQ里面，消费时也要保证其执行顺序，否则增、改、删被你将执行顺序改为删、增、改，那么本来应该数据同步过来，最后这个数据被删除的，结果搞错了顺序，最后这条数据被保存了下来，数据同步出错会引起很大生产事故<br>1、RabbitMQ<br>可能出现错乱的场景：一个Queue，多个Consumer，很明显会错乱<br>解决方案：<br>a、拆分多个Queue，每个Queue对应一个Consumer，这种方式Queue会多一些，确实比较麻烦<br>b、只要一个Queue，对应一个Consumer，然后这个Consumer内部用内存队列做排队，然后分发给底层不同的Worker来处理<br>2、Kafka<br>可能出现错乱的场景：一个Topic，一个Partition，一个Consumer,Consumer内部使用多线程处理Partition内部的消息，很明显会错乱<br>解决方案：<br>a、一个Topic，一个Partition，一个Consumer，Consumer内部使用单线程消费<br>b、一个Topic，一个Partition，一个Consumer，Partition可以写N个内存Queue，然后Consumer开启的N个线程分别消费一个Queue即可</p>
<h4 id="如果让你写一个消息队列，如何进行架构设计？"><a href="#如果让你写一个消息队列，如何进行架构设计？" class="headerlink" title="如果让你写一个消息队列，如何进行架构设计？"></a>如果让你写一个消息队列，如何进行架构设计？</h4><p>1、这个MQ得支持可伸缩性，就是在需要的时候可以快速扩容，可以增加吞吐量和容量，这就可以设计个分布式系统。参照Kafka的设计理念，一个Topic分为多个Partition，每个Partition放在一个Broker上，每个Broker放在一台机器上，每个Partition只存放对应Topic的一部分数据。如果现在的资源不够了，就给Topic增加Partition，然后做数据迁移，增加机器就可以存放更多数据，提供更高的吞吐量<br>2、这个MQ得支持落地持久化，就是消息一送达MQ，就进行磁盘持久化，只有这样才能保证进程挂掉数据也不会丢失。落地磁盘的时候要顺序写，因为这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这也是Kafka的思路<br>3、这个MQ得支持高可用性，这个可以参考Kafka的高可用保障机制。多副本，选举出Leader进行读写，其余的副本为Follower，若Leader意外挂掉，则在Follower中重新选举出Leader，即可继续对外服务<br>4、这个MQ得支持数据零丢失，这个可以Kafka的零丢失方案。a、在消费者消费的时候，设计一个类似Kafka中offset的概念，当处理完成后再手动提交此“仿offset”。b、保证每个Partition必须有至少两个副本。c、保障至少有一个Follower与Leader正常连接。c、必须是写入所有的Replica之后，才能认为生产者写成功了。d、一旦生产者写入失败，无限重试，卡在这里</p>
</div></article><div class="pagination"><span class="pagination-prev">PREV</span><span class="pagination-next">NEXT</span></div><div class="comments"></div></div><aside class="sidebar"><h3>分类标签</h3><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul><h3>最新文章</h3><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/04/28/MQ%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/">“MQ面试总结”</a></li></ul></aside></section></div><div class="extra"></div><footer class="footer"><div class="row-flex-row limit-width vh-center"><div class="copyright"><P>© 2020 <a href="/">pinkDonkey</P></div></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-80781234-1",'auto');ga('send','pageview');</script><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "//hm.baidu.com/hm.js?ee75cf111111aa99f8540efa2570970";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>