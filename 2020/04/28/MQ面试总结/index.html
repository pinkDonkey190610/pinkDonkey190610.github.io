<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> “MQ面试总结” · pinkDonkey</title><meta name="description" content="I'm a little pink donkey that keeps going ..."><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/jekyll.css"><!--[if lt IE 9]>
<script src="js/html5shiv.min.js"></script>
<script src="js/respond.min.js"></script>
<![endif]--><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="pinkDonkey" type="application/atom+xml">
</head><body><header class="row-flex-row limit-width vh-center"><a href="/" class="logo"><img src="/favicon.png"></a><nav><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-link">Home</a></li><li class="nav-list-item"><a href="/archives/" class="nav-link active">   Blog</a></li><li class="nav-list-item"><a href="https://github.com/pinkDonkey190610" target="_blank" class="nav-link">github</a></li><li class="nav-list-item"><a href="http://weibo.com/7447881909" target="_blank" class="nav-link">weibo</a></li></ul></nav></header><div class="container limit-width"><section class="row-flex-row"><div class="post"><article class="post-block"><h2 class="post-title"><a href="/2020/04/28/MQ%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/" class="post-title-link">“MQ面试总结”</a></h2><div class="post-meta"><ul class="post-tag-list"><li class="post-tag-item"><a href="/tags/面试/" class="post-tag-link">面试</a></li></ul><div class="post-time">Tuesday, April 28th 2020</div></div><div class="post-content"><p>消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠性、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。当今市面上有很多主流的消息中间件，如老牌的ActiveMQ、RabbitMQ，炙手可热的Kafka，阿里巴巴自主开发RocketMQ等。</p>
<a id="more"></a>

<h2 id="MQ的组成"><a href="#MQ的组成" class="headerlink" title="MQ的组成"></a>MQ的组成</h2><p>1、Broker：消息服务器，作为server提供消息核心服务；<br>2、Producer：消息生产者，业务的发起方，负责生产消息传输给Broker<br>3、Consumer：消息消费者，业务的处理方，负责从Broker获取消息并进行业务逻辑处理；<br>4、Topic：主题，发布订阅模式下的统一汇集地，不同生产者向Topic发送消息，由MQ服务器分发到不同的订阅者，实现消息的广播；<br>5、Queue：队列，点对点模式下，特定的生产者向特定Queue发送消息，消费者订阅特定的Queue完成指定消息的接收；<br>6、Message：消息体，根据不同通讯协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传递。</p>
<h2 id="消息的传递类型"><a href="#消息的传递类型" class="headerlink" title="消息的传递类型"></a>消息的传递类型</h2><p>1、点对点：使用Queue作为通讯载体，消息生产者生成消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。消息被消费以后，Queue中不再存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只有一个消费者可以消费。<br><img src="/images/MQ-1.png" height="555px"><br>2、发布/订阅：使用Topic作为通讯载体，消息生产者（发布）将消息发布到Topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到Topic的消息会被所有的订阅者消费。<br><img src="/images/MQ-2.png" height="555px"><br>两者的区别：Queue实现负载均衡，将Producer生产的消息发送到消息队列中，由多个消费者消费。但一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者；Topic实现了发布和订阅，当你发布一个消息，所有订阅这个Topic的服务都能的得到这个消息，所以1到N个订阅者都能得到一个消息的拷贝。</p>
<h2 id="MQ优缺点"><a href="#MQ优缺点" class="headerlink" title="MQ优缺点"></a>MQ优缺点</h2><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>1、解耦：一个业务需要多个模块共同实现，或者一条消息有多个系统需要对应处理，只需要主业务完成之后，发送一条MQ，其余模块消费MQ消息，即可实现业务，降低模块之间的耦合。<br>2、异步：主业务执行结束后从属业务通过MQ异步执行，减低业务的响应时间，提高用户体验。<br>3、消峰：高并发情况下，MQ-client提供拉模式，根据自己的处理能力，每隔一段时间或每次拉取若干条消息，实施流控，达到下游自我保护的作用，可以提高高峰期业务处理的能力，避免系统瘫痪。</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>1、系统可用性降低：系统引入的外部依赖越多，越容易挂掉，需考虑MQ瘫痪的情况。<br>2、系统复杂性提高：需要考虑消息丢失、消息重复消费、消息传递的顺序性等问题。<br>3、系统存在一致性问题：需考虑主、从业务一致性处理。</p>
<h2 id="不同MQ之间的区别"><a href="#不同MQ之间的区别" class="headerlink" title="不同MQ之间的区别"></a>不同MQ之间的区别</h2><table>
<thead>
<tr>
<th align="center">特性</th>
<th align="center">ActiveMQ</th>
<th align="center">RabbitMQ</th>
<th align="center">RocketMQ</th>
<th align="center">Kafka</th>
</tr>
</thead>
<tbody><tr>
<td align="center">单机吞吐量</td>
<td align="center">万级</td>
<td align="center">万级</td>
<td align="center">十万级</td>
<td align="center">十万级</td>
</tr>
<tr>
<td align="center">Topic数量对吞吐量的影响</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">Topic可达到几百、几千的级别，吞吐量增加后有较小幅度的下降（优势）</td>
<td align="center">Topic从几百到几千时，吞吐量会大幅度下降</td>
</tr>
<tr>
<td align="center">时效性</td>
<td align="center">毫秒级</td>
<td align="center">微秒级（优势）</td>
<td align="center">毫秒级</td>
<td align="center">毫秒级</td>
</tr>
<tr>
<td align="center">可用性</td>
<td align="center">高，基于主从架构实现高可用性</td>
<td align="center">高，基于主从架构实现高可用性</td>
<td align="center">非常高，分布式架构</td>
<td align="center">非常高，Kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td>
</tr>
<tr>
<td align="center">消息可靠性</td>
<td align="center">有较低的概率丢失数据</td>
<td align="center"></td>
<td align="center">经过参数优化设置，可以做到零丢失</td>
<td align="center">经过参数优化设置，可以做到零丢失</td>
</tr>
<tr>
<td align="center">功能支持</td>
<td align="center">MQ领域的功能极其完备</td>
<td align="center">基于erlang开发，所以并发能力很强，性能机器好，延时很低</td>
<td align="center">MQ功能较为完善，还是分布式的，扩展性好</td>
<td align="center">功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准</td>
</tr>
<tr>
<td align="center">优势</td>
<td align="center">非常成熟，功能强大，在业内大量的公司以及项目中都有应用</td>
<td align="center">erlang语言开发，性能极其好，延时很低。吞吐量到万级，MQ功能比较完备。开源提供的管理界面非常棒。社区相对比较活跃，几乎每个月都发布几个版本。国内一些互联网公司用的也比较多</td>
<td align="center">接口简单易用，阿里大规模应用过。日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展很方便，社区维护还可以，可靠性和可用性都不错，还可以支持大规模的Topic数量，支持复杂MQ业务场景。Java编写，源码便于阅读</td>
<td align="center">Kafka仅仅提供较少的核心功能，但是提供超高的吞吐量，毫秒级的延迟，极高的可用性和可靠性，分布式易扩展。Kafka最好是支撑较少的Topic数量，以保证其超高的吞吐量</td>
</tr>
<tr>
<td align="center">劣势</td>
<td align="center">偶尔会有较低概率丢失消息。社区活跃度逐渐降低、国内应用也越来越少，官方对ActiveMQ 5.x维护越来越少，几个月才发布一个版本。主要基于解耦和异步来用，较少在大规模吞吐的场景中使用</td>
<td align="center">实现机制比较重，吞吐量相比低一些。erlang语言开发，很难有实力去源码级别研究与定制。RabbitMQ集群动态扩展很麻烦</td>
<td align="center">社区活跃度相对一般，文档相对简单一些，接口不是按照标准JMS规范，有些系统要迁移时需要大量修改代码</td>
<td align="center">消息可重复消费，会对消息准确性造成极其细微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略，这个特性天然适合大数据实时计算以及日志采集</td>
</tr>
</tbody></table>
<p>综上所述：中小型公司，技术实力较为一般，技术挑战不是特别高，用RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择；大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，几乎是全世界这个领域的事实性规范。</p>
<h2 id="MQ常见问题解决方案"><a href="#MQ常见问题解决方案" class="headerlink" title="MQ常见问题解决方案"></a>MQ常见问题解决方案</h2><h4 id="引入MQ后，如何保证其高可用性？"><a href="#引入MQ后，如何保证其高可用性？" class="headerlink" title="引入MQ后，如何保证其高可用性？"></a>引入MQ后，如何保证其高可用性？</h4><p>1、RabbitMQ的高可用性（基于主从做高可用性）：<br>RabbitMQ有三种模式：单机模式、普通集群模式、镜像集群模式<br>a、单机模式：就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式（无高可用性）<br>b、普通集群模式：就是在多台机器上启动多个RabbitMQ实例，每个机器上启动一个，但是创建Queue时，只会放在一个RabbitMQ实例上，其他的每个实例都同步Queue的元数据。消费的时候，若连接到未存放Queue的实例，则该实例会从Queue所在实例上拉取数据过来（就是个普通的集群，未做到分布式，在消费消费时，有两种方式，要不消费者每次随机连接一个实例然后拉取数据，要不固定连接那个Queue所在的实例消费数据，前者有数据拉取的开销，后者存在单实例性能瓶颈的问题；若存放Queue的实例宕机了，会导致接下来其它实例无法从那个宕机的实例拉取数据，若开启了消息持久化，让RabbitMQ落地存储消息，消息不一定会丢，得等这个实例恢复了，才可以继续从这个Queue拉取数据；这个方案没有什么高可用可言，主要就是提高吞吐量的，就是让集群中多个节点来服务某个Queue的读写）<br>c、镜像集群模式：这种模式，才是所谓的RabbitMQ的高可用模式，与普通集群模式不同的就是，你创建的Queue，无论元数据还是Queue里面的消息都会存在于多个实例上，然后你每次写消息到Queue的时候，都会自动把消息同步到其他实例的Queue（好处：任何一台机器宕机，其他机器都包含完整的消息，可以继续使用。坏处：1、性能开销太大，消息同步到所有机器，导致网络带宽压力和消耗很重。2、没有扩展性可言，如果某个Queue负载过重，加机器，新增的机器也包含了这个Queue的所有数据，并没有办法线性扩展Queue（解决方法其实很简单，RabbitMQ有很好用的管理控制台，可以后台新增一个策略，这个策略是镜像集群模式的策略，可以要求数据同步到所有节点、也可以要求只同步到指定数量的节点，然后你再次创建Queue的时候，应用这个策略，就会自动将数据同步到其它的节点上去了））<br>2、Kafka的高可用：<br>多个Broker组成，每个Broker是一个节点；你每创建一个Topic,这个Topic可以划分为多个Partition，每个Partition可以存在于不同的Broker上，每个Partition就放一部分数据。这就是天然的分布式消息队列，就是说一个Topic的数据，是分散放在多个机器上的，每个机器放一部分数据（实际上RabbitMQ之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA机制而已，因为无论怎么玩儿，RabbitMQ一个Queue的数据都是放在一个节点里的，像镜像集群下，也是每个节点都放这个Queue的完整数据），Kafka0.8以前没有HA机制， 就是任何一个Broker宕机，那么Broker上的Partition就废了，无法读写，无高可用可言。Kafka0.8以后提供了HA机制，就是Replica副本机制，每个Partition的数据都会同步到其他机器上，形成自己的多个Replica副本，然后从所有的Replica会选举出一个Leader出来，生产和消费都会与这个Leader打交道，其他的Replica就是Follower，写的时候，Leader会负责把消息同步到所有的Follower上去，读的时候就直接读Leader上数据即可（为何只能读Leader，很简单，要是可以随意读写每个Follower，那么就要关心数据一致性的问题，系统复杂性太高，很容易出问题）Kafka会均匀的将一个Partition的所有Replica分布在不同的机器上，这样可以提高容错性。如果某个Broker宕机了并不会有太大问题，因为Broker上面的Partition在其他机器上都有副本的，如果这上面有某个Partition的Leader，那么此时会重新选举出一个新的Leader出来，继续读写这个新的Leader即可，这就是所谓的高可用性。写数据的时候，生产者就写Leader，然后Leader将数据落地写入本地磁盘，接着其它Follower自己主动从Leader来pull数据。一旦所有Follower同步好数据，就会发送ack给Leader，Leader收到所有Follower的ack之后，就会返回写成功的消息给生产者（这只是其中一种模式）消费的时候，只会从Leader去读，但是只有一个消息已经被所有Follower都同步成功返回ack的时候，这个消息才会被消费者读到 </p>
<h4 id="引入MQ后，如何保证消息消费时的幂等性？"><a href="#引入MQ后，如何保证消息消费时的幂等性？" class="headerlink" title="引入MQ后，如何保证消息消费时的幂等性？"></a>引入MQ后，如何保证消息消费时的幂等性？</h4><p>1、为何会出现消息重复消费的情况？<br>以Kafka举例，其存在一个offset的概念，就是每个消息写进去都有一个offset来代表它的序号，然后Consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，通知Kafka这些消息已经被消费过了，如果我重启了什么的，就继续上次消费到的offset来继续消费。若在offset还未提交的时候，进程被kill掉了，那么就会造成Consumer明明已经消费了某些消息，但Kafka并不会接收到offset通知，此时若重启，那么Kafka就会按照已经接收到的offset来判断消息消费的起点，那么已经消费却未成功发送offset的消息就会被再次消费，造成消息重复消费的问题<br>2、如何保证消息队列的幂等性？<br>保证MQ的消费是幂等性的，需要结合具体的业务来看，简单举例几种情况：<br>a、比如你拿个数据要写库操作，那么你可以先根据主键查一下，如果这个数据已经存在，那么就不插入，只需要update一下就好<br>b、比如你是写入Redis的，那没问题，反正每次都是set，天然幂等性<br>c、若不是上面两种场景，你可以让生产者发送数据的时候加一个全局唯一的id，类似订单id之类的东西，然后你消费的时候，先根据id去比如Redis里查一下之前是否消费过？若未消费过，就继续处理，然后这个id写入Redis，若已经消费过，就不进行后续处理，保证相同消息不被重复消费即可<br>d、基于数据库唯一键来保证重复数据不会重复插入多条</p>
</div></article><div class="pagination"><span class="pagination-prev">PREV</span><span class="pagination-next">NEXT</span></div><div class="comments"></div></div><aside class="sidebar"><h3>分类标签</h3><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul><h3>最新文章</h3><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/04/28/MQ%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/">“MQ面试总结”</a></li></ul></aside></section></div><div class="extra"></div><footer class="footer"><div class="row-flex-row limit-width vh-center"><div class="copyright"><P>© 2020 <a href="/">pinkDonkey</P></div></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-80781234-1",'auto');ga('send','pageview');</script><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "//hm.baidu.com/hm.js?ee75cf111111aa99f8540efa2570970";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>